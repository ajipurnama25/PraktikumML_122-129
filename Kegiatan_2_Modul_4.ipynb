{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kegiatan 2 Modul 4.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUtOmn/uFrf6oToQay5quY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajipurnama25/PraktikumML_122-129/blob/main/Kegiatan_2_Modul_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZDpo8JGN-9v"
      },
      "source": [
        "#import library \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, cv2, shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense, Conv2D, MaxPool2D, Flatten,BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjyFshM2OKJ5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHaPff-HOKMj"
      },
      "source": [
        "# Definisikan path kaggle json\n",
        "# Sesuaikan dengan path anda\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/My Drive/data_tugas2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj5_q2LoOKOn"
      },
      "source": [
        "# Ubah lokasi direktori kerja\n",
        "# Sesuaikan dengan path anda\n",
        "%cd /content/drive/My Drive/data_tugas2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O8GEUFWOKQw"
      },
      "source": [
        "# Cek apakah api sudah terbaca oleh sistem\n",
        "!ls  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsIHiFfRgwvM"
      },
      "source": [
        "!kaggle datasets download -d vbookshelf/rice-leaf-diseases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7r3e8U_OKYu"
      },
      "source": [
        "# Ekstrak file dataset dan hapus file zip dataset agar tidak memakan banyak tempat.\n",
        "!unzip \\*.zip &> /dev/null && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaL2k9R7OV7M"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiyVRQgaOV4L"
      },
      "source": [
        "os.makedirs('/content/drive/My Drive/data_tugas2/Dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edtEc5TZmHOs"
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuZlHY70eyCG"
      },
      "source": [
        "import splitfolders\n",
        "\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/data_tugas2/rice_leaf_diseases'\n",
        "data_dir = '/content/drive/My Drive/data_tugas2/Dataset'\n",
        "\n",
        "splitfolders.ratio(base_dir, output=data_dir, seed=1337, ratio=(.8, .19, .01),group_prefix=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nivDolJ05bWN"
      },
      "source": [
        "AUGMENTASI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLeQ_8f-nNES"
      },
      "source": [
        "# TULIS KODE ANDA DISINI\n",
        "datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3ZN_BKbnNPd"
      },
      "source": [
        "input_shape = (224, 224)\n",
        "\n",
        "train = '/content/drive/MyDrive/data_tugas2/Dataset/train'\n",
        "train_generator = datagen.flow_from_directory(train,\n",
        "                                              target_size=input_shape,\n",
        "                                              class_mode='categorical',\n",
        "                                              batch_size=32,\n",
        "                                              color_mode='rgb',\n",
        "                                              shuffle= True)\n",
        "\n",
        "validation = '/content/drive/MyDrive/data_tugas2/Dataset/val'\n",
        "validation_generator = datagen.flow_from_directory(validation,\n",
        "                                              target_size=input_shape,\n",
        "                                              class_mode='categorical',\n",
        "                                              batch_size=32,\n",
        "                                              color_mode='rgb',\n",
        "                                              shuffle= True)\n",
        "\n",
        "test = '/content/drive/MyDrive/data_tugas2/Dataset/test'\n",
        "test_generator = datagen.flow_from_directory(test,\n",
        "                                              target_size=input_shape,\n",
        "                                              batch_size=32,\n",
        "                                              color_mode='rgb',\n",
        "                                              shuffle= False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQw8Wq9ZnuYS"
      },
      "source": [
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import InputLayer, Dense, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, AveragePooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ev5dHHWnxEk"
      },
      "source": [
        "# Model building\n",
        "#Instatiating A convnet\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(InputLayer(input_shape=[224, 224, 3]))\n",
        "model.add(Conv2D(filters=1, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size = (3,3), strides=2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=3, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size = (3,3), strides=2))\n",
        "\n",
        "model.add(Conv2D(filters=1, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size = (3,3), strides=2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONzUyrPWnw8y"
      },
      "source": [
        "# Fully Connected Layer\n",
        "model.add(Dense(1024,activation=\"softmax\"))\n",
        "model.add(Dense(512,activation=\"softmax\"))\n",
        "model.add(Dense(3, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aom4rwTcn2u3"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkLU2wWcpKJJ"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.01), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QfLtU6ApLZT"
      },
      "source": [
        "H = model.fit_generator(train_generator, epochs = 100, validation_data = validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emz8n923E2M-"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Loss Plot\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 100), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Accuracy Plot\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Acc\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynKYHt7-elSy"
      },
      "source": [
        "model2 = Sequential()\n",
        "\n",
        "model2.add(InputLayer(input_shape=[150,150,3]))\n",
        "model2.add(Conv2D(filters=32, kernel_size=3, strides=2, activation='relu'))\n",
        "model2.add(AveragePooling2D(pool_size=2, padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "model2.add(Conv2D(filters=16, kernel_size=3, strides=2, activation='relu'))\n",
        "model2.add(AveragePooling2D(pool_size=2, padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "\n",
        "model2.add(Conv2D(filters=8, kernel_size=3, strides=2, activation='relu'))\n",
        "model2.add(AveragePooling2D(pool_size=2, padding='same'))\n",
        "\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(GlobalAveragePooling2D())\n",
        "model2.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw2UcH0SelNO"
      },
      "source": [
        "# Fully Connected Layer\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "model2.add(Dense(6, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtnEgWFsy9n5"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwftnAV6y9l0"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.01), \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nFMIOMzfYjD"
      },
      "source": [
        "H = model.fit_generator(train_generator, epochs = 100, validation_data = validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAEioPBofYgD"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Loss Plot\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 100), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Accuracy Plot\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Acc\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiJpo1IP6a1I"
      },
      "source": [
        "hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtLekDMB6bmz"
      },
      "source": [
        "# Tulis Program Anda Disini!\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CexfPeWI6jEU"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjQmTNIc6jMj"
      },
      "source": [
        "!rm -rf ./logs/ "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqJ2GbCo6jKO"
      },
      "source": [
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([64, 128]))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.2, 0.25))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd', 'adadelta']))\n",
        "\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIA0NwlO6jHy"
      },
      "source": [
        "xvl, yvl = zip(*(validation_generator[i] for i in range(len(validation_generator))))\n",
        "x_val, y_val = np.vstack(xvl), np.vstack(yvl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK8Y1hef6q2L"
      },
      "source": [
        "def train_test_model(hparams):\n",
        "  model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16, (3, 3), \n",
        "                                                             activation=tf.nn.relu, \n",
        "                                                             input_shape=(150,150,3)),\n",
        "                                      tf.keras.layers.BatchNormalization(),\n",
        "                                      tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "                                      tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "                                      tf.keras.layers.Conv2D(32, (3, 3), \n",
        "                                                             activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.BatchNormalization(),\n",
        "                                      tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "                                      tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "                                      tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "                                      tf.keras.layers.Conv2D(64, (3, 3), \n",
        "                                                             activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.BatchNormalization(),\n",
        "                                      tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "                                      tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "                                      tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "                                      tf.keras.layers.Flatten(),\n",
        "                                      tf.keras.layers.Dense(hparams[HP_NUM_UNITS], \n",
        "                                                            activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                      tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "                                      tf.keras.layers.Dense(6, activation=tf.nn.softmax),\n",
        "                                      ])\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=hparams[HP_OPTIMIZER],\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "  )\n",
        "\n",
        "  model.fit(train_generator, \n",
        "            validation_data=validation_generator, \n",
        "            epochs=50,\n",
        "            )\n",
        "  _, accuracy = model.evaluate(x_val, y_val)\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjIPpoET6qvv"
      },
      "source": [
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Oyi4BrX6qj_"
      },
      "source": [
        "session_num = 0\n",
        "\n",
        "for num_units in HP_NUM_UNITS.domain.values:\n",
        "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
        "    for optimizer in HP_OPTIMIZER.domain.values:\n",
        "      hparams = {\n",
        "          HP_NUM_UNITS: num_units,\n",
        "          HP_DROPOUT: dropout_rate,\n",
        "          HP_OPTIMIZER: optimizer,\n",
        "      }\n",
        "      run_name = \"run-%d\" % session_num\n",
        "      print('--- Starting trial: %s' % run_name)\n",
        "      print({h.name: hparams[h] for h in hparams})\n",
        "      run('logs/hparam_tuning/' + run_name, hparams)\n",
        "      session_num += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhYmC_LU6uGx"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Loss Plot\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 100), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, 100), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Accuracy Plot\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Acc\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}